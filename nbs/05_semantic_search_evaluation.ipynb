{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp semantic_search_evaluator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Set, List, Tuple\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from enum import Enum\n",
    "from torch import Tensor\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data\"\n",
    "questions_file = f\"{base_dir}/evaluation_dataset/sample_queries_cleaned.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries = pd.read_json(questions_file, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARTIOM DRUMEA Sent You a Message Behance Basic...</td>\n",
       "      <td>&lt;010001809eb828f6-b2888a42-bd74-4f16-b366-cf0e...</td>\n",
       "      <td>\"message from ARTIOM DRUMEA on Behance\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fwd: CIIS Commencement 2021: Join us on May 1!...</td>\n",
       "      <td>&lt;BY5PR22MB208353712894331A58D4D4C6E72F9@BY5PR2...</td>\n",
       "      <td>\"CIIS Commencement 2021 details\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your Digest: From the Mac Startup Tone to the ...</td>\n",
       "      <td>&lt;esuh8huNSw2sRLJpnIw4HQ@ismtpd0012p1iad2.sendg...</td>\n",
       "      <td>\"OneZero digital digest\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ARTIOM DRUMEA Sent You a Message Behance Basic...   \n",
       "1  Fwd: CIIS Commencement 2021: Join us on May 1!...   \n",
       "2  Your Digest: From the Mac Startup Tone to the ...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  <010001809eb828f6-b2888a42-bd74-4f16-b366-cf0e...   \n",
       "1  <BY5PR22MB208353712894331A58D4D4C6E72F9@BY5PR2...   \n",
       "2  <esuh8huNSw2sRLJpnIw4HQ@ismtpd0012p1iad2.sendg...   \n",
       "\n",
       "                                     query  \n",
       "0  \"message from ARTIOM DRUMEA on Behance\"  \n",
       "1         \"CIIS Commencement 2021 details\"  \n",
       "2                 \"OneZero digital digest\"  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index_path = f\"{base_dir}/embeddings_distilbert_base_uncased_mean_pooling/embeddings_index.npy\"\n",
    "embeddings_index = np.load(embeddings_index_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, query: \"message from ARTIOM DRUMEA on Behance\", id: <010001809eb828f6-b2888a42-bd74-4f16-b366-cf0e2ff63842-000000@email.amazonses.com>\n",
      "idx: 1, query: \"CIIS Commencement 2021 details\", id: <BY5PR22MB208353712894331A58D4D4C6E72F9@BY5PR22MB2083.namprd22.prod.outlook.com>\n",
      "idx: 2, query: \"OneZero digital digest\", id: <esuh8huNSw2sRLJpnIw4HQ@ismtpd0012p1iad2.sendgrid.net>\n",
      "idx: 3, query: \"ASP.NET Core features email\", id: <RL8EBdcFTSSO7q2dFdUCxw@ismtpd0023p1iad2.sendgrid.net>\n",
      "idx: 4, query: \"Outerbounds ML Platform improvement email from Will\", id: <CAKmoF_9cZB-5TjiELdaSpKsAsQ2q2pgpisO_kb+7o=q+F-y81A@mail.gmail.com>\n",
      "idx: 5, query: \"scan srtnica mama\", id: <20240122115635.1ab5b942d614a95a@sndmail.mail.io>\n",
      "idx: 6, query: \"Design Within Reach recommendation survey\", id: <01000176860d2f7a-b6ea6de5-ab4d-40a5-b800-4bc46870cff0-000000@email.amazonses.com>\n",
      "idx: 7, query: \"Uber account deletion confirmation\", id: <7948fea5-a34b-4993-a6ea-55742f2e4729@mail.uber.com>\n",
      "idx: 8, query: \"Pixlr Genesis New Year email 2022\", id: <0100017e3b06c064-4aabc442-d30b-434e-911b-b8aabd2fff22-000000@email.amazonses.com>\n",
      "idx: 9, query: \"United Airlines eTicket receipt for confirmation OY874S\", id: <1846733286.4321.1627459030146.JavaMail.tibco@vcld34rpamubw01.ual.com>\n",
      "idx: 10, query: \"U-Haul supplies order confirmation\", id: <c49c66$40jh8@e.uhaul.com>\n",
      "idx: 11, query: \"U-Haul order 8FA92E54\", id: <ab73a6$l3gu8@t.uhaul.com>\n",
      "idx: 12, query: \"energy efficiency report comparison October 2023\", id: <454816537.364583.1698716761602@ip-10-0-63-183.ec2.internal>\n",
      "idx: 13, query: \"Java Android Developer job opportunity\", id: <667637536.1614330102971.JavaMail.cfservice@sl122app5>\n",
      "idx: 14, query: \"account disabled cui@mail.io\", id: <20241226020136.38bb92eaf295fedc@sndmail.mail.io>\n",
      "idx: 15, query: \"SmartMusic signup confirmation\", id: <ZNHYN8GCGWBZ2CRJKPYMCS@mail.gmail.com>\n",
      "idx: 16, query: \"Maker Fest winner announcement Goodnight Zoom\", id: <55f7af42.BAAAAMcbnikAAcgxVo4AAAeAJyoAAAAIijYAAAAAAAYklQBeqEKZ@mailjet.com>\n",
      "idx: 17, query: \"Renewal by Andersen consultation\", id: <ZF3lf1bGTw-Ct-Y9ADdPwrwj0Q17ftAHg-46.4.187.81@ismtpd0003p1iad1.sendgrid.net>\n",
      "idx: 18, query: \"GLS 508912991 delivery notice\", id: <CAMCKGwRNnNBCy2t8jEFUmGh6C0SvM8dE_W_+Sns86-WMnUY+4A@mail.gmail.com>\n",
      "idx: 19, query: \"Chrysalis Cloud trial expired email\", id: <OjtXZA30R6KQY9wc1mEDDw@geopod-ismtpd-3-5>\n",
      "idx: 20, query: \"Walgreens vaccine first dose reminder\", id: <bfrxtuybf83cqyauh40e9a42zst06d.1567565609.645@mta715.rxorder.walgreens.com>\n",
      "idx: 21, query: \"Budget Rent A Car reservation reminder September 2021\", id: <0e8a3c65-0b58-46b2-a194-fed4a9db5c96@ind1s06mta1264.xt.local>\n",
      "idx: 22, query: \"verify Hue account email igor.amplio@gmail.com\", id: <820c3561.CAAAAaL1ODEAAAAAAAAAALMJ_ucAAAAAAAEAAAAAAAwGewBgcP-2@mailjet.com>\n",
      "idx: 23, query: \"Jamf Now free devices offer\", id: <84d5d3c8183750f37b56a5743.c68700374e.20190813161912.1475284f16.5ffbdce6@mail84.atl31.mcdlv.net>\n",
      "idx: 24, query: \"Mailgun Pathwire introduction announcement\", id: <dgOrwASrwAQDAAF3YtRwhu-qEYGNkrRf6xI.1612271025@mailgun.com>\n",
      "idx: 25, query: \"nature photo email\", id: <01010172af5ec35f-75ff355b-3743-40b0-8893-e69bea21a19d-000000@us-west-2.amazonses.com>\n",
      "idx: 26, query: \"Photo ID pickup details for Igor Rendulic\", id: <CADUk_sUA_6zF2-etTkUFcku1yHSBbem0efOd2cSo6MDXZ7m-4Q@mail.gmail.com>\n",
      "idx: 27, query: \"Intel CVE announcements DigitalOcean\", id: <1310034435.367832456.1580165922817.JavaMail.mktmail@abmas01.marketo.org>\n",
      "idx: 28, query: \"encrypted message reply\", id: <PzxGIyXQrdzOs6kLtlWS619qDytCrkWzULGNlVNElU-4NKqGhnEW6hFqIr6wigvZN7F50Q9c6eIxsAzX_RPTPB8TbmgbHK-Tmge6EHM2lOc=@proton.me>\n",
      "idx: 29, query: \"Log10 LLMOps platform details April 2024\", id: <C__1AD7sTVu7vqlEQAvCLQ@geopod-ismtpd-1>\n",
      "idx: 30, query: \"unread messages in Gitter\", id: <7OW2Q344Z2_5fbc198ceec0d_505b45b4596cc_sprut@zendesk.com>\n",
      "idx: 31, query: \"Kars4Kids summer safety tips email\", id: <1624374658032.52345235.145785030.26996547477@backend.cp20.com>\n",
      "idx: 32, query: \"Vitalik tweet about Igor highlights\", id: <79.71.44462.6712A1D5@twitter.com>\n",
      "idx: 33, query: \"meeting with Domingo Guerra after June 19, 2019\", id: <BY5PR16MB3352A7F63F6FD6214E509C498FE40@BY5PR16MB3352.namprd16.prod.outlook.com>\n",
      "idx: 34, query: \"Existential Physics book purchase confirmation from Amazon\", id: <CADsbVtv=6Lwv=e8Cq8VO8DundD5KNZoJR0x3gEhKk8QrFDzpZw@mail.gmail.com>\n",
      "idx: 35, query: \"Rechnung vom 10.12.2023 autoUnion\", id: <d0ced8db81b4c7be60dc0641c26f38e4@swift.generated>\n",
      "idx: 36, query: \"Instagram Terms of Use update December 2020\", id: <5920ba4a3aa011eb9409b8599fb40e6e-536617e0@mail.instagram.com>\n",
      "idx: 37, query: \"skinny pill weight loss\", id: <ZF3lf1bGTw-Ct-Y9ADdPwrwj0Q1N15zHg-208.67.253.210@ismtpd0003p1iad1.sendgrid.net>\n",
      "idx: 38, query: \"Zoom invitation on April 21, 2021\", id: <00000000000083aa1705c07d0335@google.com>\n",
      "idx: 39, query: \"NUGGS chicken nuggets launch news\", id: <34c82535.CAAAAEi-CMgAAAYrxKAAAAeAJyoAAAAIijYAAAAAAAYklQBdJfk0@mailjet.com>\n",
      "idx: 40, query: \"Mr. Cooper mortgage statement\", id: <48520135-ae0d-4613-8041-73e43a53e4e2@ind1s06mta1526.xt.local>\n",
      "idx: 41, query: \"Your Digest: PWA capabilities for React or Angular\", id: <FZS6fnpkTC-6x-QxkLCdKg@ismtpd0131p1mdw1.sendgrid.net>\n",
      "idx: 42, query: \"video meeting link\", id: <CAOJVsLS5c=SoR3PnG3oUDBS9zHyvZuxdC+pRkyJ6LYJHFQbrcw@mail.gmail.com>\n",
      "idx: 43, query: \"questions about Babylist baby registry\", id: <hcqKuCtnQsGL8O23a3yg6A@ismtpd0092p1iad2.sendgrid.net>\n",
      "idx: 44, query: \"Kars4Kids real estate donation opportunity\", id: <1605812638342.47720910.140660047.26996547477@backend.cp20.com>\n",
      "idx: 45, query: \"Mailio NFTs daily summary September 2022\", id: <26e5735c-e6c1-40e9-8d0c-1909ae77eb36@mtasv.net>\n",
      "idx: 46, query: \"Front team work from home tips\", id: <Eo6k0rQjR0mz3R3LZ0bjOQ@ismtpd0005p1iad1.sendgrid.net>\n",
      "idx: 47, query: \"Zoom meeting summary discussion points May 29 2024\", id: <CAMTqtyqDYUr1Jox6rs4jDuBNU49Sp4rxU-v17Jqno+DEDje5cg@mail.gmail.com>\n",
      "idx: 48, query: \"Office Depot receipt 2021\", id: <9e5e93fa-33fa-4b1d-aada-79a0aec8a7c0@ind1s06mta1303.xt.local>\n",
      "idx: 49, query: \"Web Components resources by Igor Rendulic\", id: <20240823211225.9c064541ef9ead5e@igor.technology>\n",
      "idx: 50, query: \"Bank of America financial center hours update\", id: <d8de5acf-4538-4b83-99d3-4642dac331fc@las1s04mta1080.xt.local>\n",
      "idx: 51, query: \"How to sell NFT on OpenSea\", id: <20220104105755.b2c1ed67dd0e8810@hello.mailio.io>\n",
      "idx: 52, query: \"Disney+ subscription cancellation email\", id: <81503529-d4b5-4fcc-8f88-2e1d99a11fa8@dfw1s10mta1073.xt.local>\n",
      "idx: 53, query: \"migration of mailiomail.com to Squarespace\", id: <84510cb3baa6aa8c49a5b072628dce3d46218f72-20282367-111446501@google.com>\n",
      "idx: 54, query: \"DigitalOcean deploy conference details\", id: <iS86RqkeSqm9vEGOdbfIiA@geopod-ismtpd-2-1>\n",
      "idx: 55, query: \"Updated invitation Igor - Ryan Catchup Oct 18, 2024\", id: <calendar-98f6cbcb-d8c6-4bda-892c-3e7ce86382ec@google.com>\n",
      "idx: 56, query: \"Kraken crypto tax loss harvesting email\", id: <20191230231943.1.5108A772412CB20A@email.kraken.com>\n",
      "idx: 57, query: \"Akontacija DDPO junij 2020\", id: <CAKOtCD+eYbwYfPVa6J+3Kk64jncgnEPVJ3SNBt-Q85E4pPGT-w@mail.gmail.com>\n",
      "idx: 58, query: \"racun za april 2020\", id: <CAPnNMAgkQeSBCTtSP-EksnPx0mJFNU5mmFDMkT9nyCcGooS7XA@mail.gmail.com>\n",
      "idx: 59, query: \"Facebook password reset code\", id: <51be8cda-1df7-11ef-a867-eb2cfb6e46ba@facebookmail.com>\n",
      "idx: 60, query: \"CueMateAPISpec API changes from Pat\", id: <C89CF4E5-345C-4E16-83F5-60DB6F3EADF5@gmail.com>\n",
      "idx: 61, query: \"San Francisco Java User Group workshop December 2023\", id: <605171868.7483661.1608066625818.JavaMail.nobody@57b26e617362>\n",
      "idx: 62, query: \"Soniox hiring engineers Klemen Simonic\", id: <CA+8gbzp=D9sQnZ4YDZTxFMua6xP638wQGDr6AN9K5K6MQFQPzg@mail.gmail.com>\n",
      "idx: 63, query: \"Airbnb Luxe news\", id: <84d5d3c8183750f37b56a5743.ba5a9b1d3a.20190628160417.8537d1f823.c4191f8d@mail202.atl81.rsgsv.net>\n",
      "idx: 64, query: \"Axis Developer Community overview\", id: <15ff133c-debb-41a8-aff5-91ecb466b7e3@atl1s07mta3031.xt.local>\n",
      "idx: 65, query: \"Warby Parker eye exam appointment August 5\", id: <20210804192530.1.95C11F641A71EAC2@mail3.warbyparker.com>\n",
      "idx: 66, query: \"DMARC report from Amazon SES September 2020\", id: <010101746884bf4e-896d6e57-f03d-4278-8d5d-02b4d9c63598-000000@us-west-2.amazonses.com>\n",
      "idx: 67, query: \"NFTHack Hackathon March 2023\", id: <Nvq-mlD6QHWc5o7RgxHe2Q@ismtpd0026p1iad2.sendgrid.net>\n",
      "idx: 68, query: \"Burning Spear Xavier Rudd tickets\", id: <DFEC73CF-7AB0-49A7-AD70-ACADBDDBFA6F@gmail.com>\n",
      "idx: 69, query: \"mailio first article Indonesia\", id: <01010176a4bb975b-7c3f4c65-24ae-4336-b31f-e3de17531311-000000@us-west-2.amazonses.com>\n",
      "idx: 70, query: \"Nod browser extension for Google Meet\", id: <ba6672e1.EAAAAMETw9QAAAYr2yYAAAeAJyoAAAAIijYAAAAAAAYklQBelIQy@mailjet.com>\n",
      "idx: 71, query: \"Whitney Peak Hotel reservation details\", id: <4F114G64lczy5N@mailrouter-106.ams4.prod.booking.com>\n",
      "idx: 72, query: \"Pat asking how i'm doing with Ukrain war\", id: <8E9B8A30-3AC3-4989-8E67-E748DF9C057F@gmail.com>\n",
      "idx: 73, query: \"Welcome email from LuminPDF\", id: <20201225215837.1.8B7906A0015C813C@luminpdf.com>\n",
      "idx: 74, query: \"Covered California one-time passcode\", id: <1888184062.11446.1594783963009.JavaMail.oracle@pdclnap089>\n",
      "idx: 75, query: \"homunculus meaning\", id: <010101843ba25fdb-fb178f9b-82fa-4381-8efb-2522782b6d72-000000@us-west-2.amazonses.com>\n",
      "idx: 76, query: \"Customer Acquisition and Retention Weekly Issue 281 February 2020\", id: <cm.0700117306607.xjrthht.qujhldltu.i@cmail19.com>\n",
      "idx: 77, query: \"Google Cloud Service Account key exposure policy change June 2024\", id: <3fb39394b39a541ff42b72a4eab3fa906f72b323-20314590-111492444@google.com>\n",
      "idx: 78, query: \"questions about real estate closing and commissions\", id: <01010180a43e83c5-16a54c9d-9508-4efe-9cac-a21ea4cd1aff-000000@us-west-2.amazonses.com>\n",
      "idx: 79, query: \"Craigslist sofa posting email May 2019\", id: <CAGbyn1Rmk5feGTYMOnzpY6CztTBb7Lsf2aRrOVCbeZFtfHZ5UQ@mail.gmail.com>\n",
      "idx: 80, query: \"Apple archive nostalgia\", id: <f1e9d3b2.CAAAAJtNfhkAAAYr0uYAAAeAJyoAAAAIijYAAAAAAAYklQBeIb6u@mailjet.com>\n",
      "idx: 81, query: \"Igor Rendulic Kiln Membership Agreement\", id: <20220228181618.a8386619804eefb8@mail.hellosign.com>\n",
      "idx: 82, query: \"Machine Learning resources by Igor Rendulic\", id: <20240220215448.985812f423015a7e@igor.technology>\n",
      "idx: 83, query: \"PETKIT review not posted Amazon\", id: <0100017970e9a5ce-9cfea81d-5fa4-45c6-8fc3-39c5225158a5-000000@email.amazonses.com>\n",
      "idx: 84, query: \"email test for albert\", id: <01010177190bb8d8-9ca1271d-d304-44d3-b815-c9117b339a83-000000@us-west-2.amazonses.com>\n",
      "idx: 85, query: \"Netflix Hangouts\", id: <84d5d3c8183750f37b56a5743.c68700374e.20190708162441.0519899f8d.6d1f6d2a@mail124.atl261.mcdlv.net>\n",
      "idx: 86, query: \"Victor Lee Medium follow notification\", id: <CLKoCjEQSgeMESRcBxDfBw@ismtpd0043p1mdw1.sendgrid.net>\n",
      "idx: 87, query: \"latest blog update\", id: <CADUk_sUM8-GVrYOOqx5uTgf5Cje4urmoYC_CM8R-Ecth+JPxfA@mail.gmail.com>\n"
     ]
    }
   ],
   "source": [
    "# contruct the ground truth dictionary from the dataframe\n",
    "\n",
    "ground_truth = dict[int, Set[int]]()\n",
    "for idx, row in df_queries.iterrows():\n",
    "    email_id = row[\"id\"]\n",
    "    print(f\"idx: {idx}, query: {row['query']}, id: {email_id}\")\n",
    "    # find in embeddings index it's index\n",
    "    emb_index_set = set(np.where(embeddings_index == email_id)[0])\n",
    "    ground_truth[idx] = emb_index_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6391}\n",
      "[1320 1321 1322]\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth[19])\n",
    "# embeddings_index[2712]\n",
    "print(np.where(embeddings_index == \"<CPZP284MB058472D9136C52B8957CB8B192C69@CPZP284MB0584.BRAP284.PROD.OUTLOOK.COM>\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SimilarityFunction(Enum):\n",
    "    COSINE = \"cosine\"\n",
    "    DOT_PRODUCT = \"dot\"\n",
    "    EUCLIDEAN = \"euclidean\"\n",
    "\n",
    "class MailioInformationRetrievalEvaluator:\n",
    "    \"\"\"\n",
    "    Insipired by on https://github.com/UKPLab/sentence-transformers/blob/v3.4-release/sentence_transformers/evaluation/InformationRetrievalEvaluator.py\n",
    "    Gives me a bit more le-way to customize creation of query embeddings and corpus embeddings\n",
    "    Also simplifies the code a bit\n",
    "\n",
    "    Given a set of queries and a large corpus set. It will retrieve for each query the top-k most similar document. It measures\n",
    "    Mean Reciprocal Rank (MRR), Recall@k, and Normalized Discounted Cumulative Gain (NDCG)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        ground_truth:Dict[int, Set[int]],  # query_index => Set[corpus_index]\n",
    "        corpus_embeddings: Tensor, # embeddingns of corpus_index\n",
    "        query_embeddings: Tensor, # embeddings of query_index\n",
    "        mrr_at_k: List[int] = [10],\n",
    "        ndcg_at_k: List[int] = [10],\n",
    "        accuracy_at_k: List[int] = [1, 3, 5, 10],\n",
    "        precision_recall_at_k: List[int] = [1, 3, 5, 10],\n",
    "        map_at_k: List[int] = [100],\n",
    "        similarity_functions = [SimilarityFunction.COSINE],\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the InformationRetrievalEvaluator.\n",
    "        Args:\n",
    "            corpus_embeddings (Tensor): A tensor of shape (N, D) containing the document embeddings.\n",
    "            query_embeddings (Tensor): A tensor of shape (M, D) containing the query embeddings.\n",
    "            ground_truth (Dict[str, Set[str]]): A dictionary mapping query index to a set of relevant document indexes.\n",
    "            mrr_at_k (List[int]): A list of integers representing the values of k for MRR calculation. Defaults to [10].\n",
    "            ndcg_at_k (List[int]): A list of integers representing the values of k for NDCG calculation. Defaults to [10].\n",
    "            accuracy_at_k (List[int]): A list of integers representing the values of k for accuracy calculation. Defaults to [1, 3, 5, 10].\n",
    "            precision_recall_at_k (List[int]): A list of integers representing the values of k for precision and recall calculation. Defaults to [1, 3, 5, 10].\n",
    "            map_at_k (List[int]): A list of integers representing the values of k for MAP calculation. Defaults to [100].\n",
    "        \"\"\"\n",
    "        self.corpus_embeddings = corpus_embeddings\n",
    "        self.query_embeddings = query_embeddings\n",
    "        self.ground_truth = ground_truth\n",
    "        self.mrr_at_k = mrr_at_k\n",
    "        self.ndcg_at_k = ndcg_at_k\n",
    "        self.accuracy_at_k = accuracy_at_k\n",
    "        self.precision_recall_at_k = precision_recall_at_k\n",
    "        self.map_at_k = map_at_k\n",
    "        self.similarity_functions = similarity_functions\n",
    "        self.problematic_queries = set()\n",
    "\n",
    "    def run(self):\n",
    "        return self.compute_metrices()\n",
    "\n",
    "    def get_problematic_queries(self):\n",
    "        return self.problematic_queries\n",
    "\n",
    "    def compute_metrices(self):\n",
    "        \"\"\"\n",
    "        Computes the evaluation metrics.\n",
    "        Args:\n",
    "            top_k (int): The number of retrieved documents for which to compute the evaluation metrics. Defaults to 10.\n",
    "        Returns:\n",
    "            Dict[str, Dict[str, float]]: A dictionary mapping metric names to dictionaries mapping metric values to scores.\n",
    "        \"\"\"\n",
    "        max_k = max(\n",
    "            max(self.mrr_at_k),\n",
    "            max(self.ndcg_at_k),\n",
    "            max(self.accuracy_at_k),\n",
    "            max(self.precision_recall_at_k),\n",
    "            max(self.map_at_k),\n",
    "        )\n",
    "        # prepare the query result list for each query and each score function\n",
    "        self.queries_result_list = {}\n",
    "        \n",
    "        metrics = {}\n",
    "        for sim_fn in self.similarity_functions:\n",
    "            similarity_name = str(sim_fn.value)\n",
    "            queries_results = self.compute_similarity_function_product(sim_fn, top_k=max_k)\n",
    "            similarity_metrics = self.compute_metrics(queries_results)\n",
    "            metrics[similarity_name] = similarity_metrics\n",
    "        return metrics\n",
    "    \n",
    "    def compute_similarity_function_product(self, similarity_function: SimilarityFunction, top_k: int = 100) -> Dict[int, List[Tuple[float, int]]]:\n",
    "        \"\"\"\n",
    "        Computes the evaluation metrics for a given similarity function.\n",
    "        Args:\n",
    "            similarity_function (SimilarityFunction): The similarity function to use for computing the similarity between queries and documents.\n",
    "            top_k (int): The number of retrieved documents for which to compute the evaluation metrics. Defaults to 10.\n",
    "        Returns:\n",
    "            Dict[int, List[Tuple[float, int]]] : A dictionary mapping query indexes to a list of tuples containing the similarity score and the document index.\n",
    "        \"\"\"\n",
    "\n",
    "        query_results = {}\n",
    "        \n",
    "        # compute the similarity between each query and each document\n",
    "        if similarity_function == SimilarityFunction.COSINE:\n",
    "            for query_index in range(len(self.query_embeddings)):\n",
    "                query_embedding = self.query_embeddings[query_index]\n",
    "                similarity = F.cosine_similarity(query_embedding, self.corpus_embeddings, dim=1)\n",
    "                scores, indices = similarity.topk(top_k, dim=0)\n",
    "                s = scores.cpu().numpy().ravel()\n",
    "                i = indices.cpu().numpy().ravel()\n",
    "                query_results[query_index] = [(s, i) for s, i in zip(s, i)]\n",
    "                \n",
    "        return query_results    \n",
    "\n",
    "    def compute_metrics(self, queries_results: Dict[int, List[Tuple[float, int]]]):\n",
    "        \"\"\"\n",
    "        Computes the evaluation metrics for a given similarity function.\n",
    "        Args:\n",
    "            queries_results (Dict[int, List[Tuple[float, int]]]): A dictionary mapping query indexes to a list of tuples containing the similarity score and the document index.\n",
    "        Returns:\n",
    "            Dict[str, Dict[str, float]]: A dictionary mapping metric names to dictionaries mapping metric values to scores.\n",
    "        \"\"\"\n",
    "        # Init score computation values\n",
    "        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n",
    "        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n",
    "        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n",
    "        MRR = {k: 0 for k in self.mrr_at_k}\n",
    "        ndcg = {k: [] for k in self.ndcg_at_k}\n",
    "        AveP_at_k = {k: [] for k in self.map_at_k}\n",
    "\n",
    "        # queries not in top 3\n",
    "        self.problematic_queries = set()\n",
    "\n",
    "        # Compute scores on results\n",
    "        for query_index, results in queries_results.items():\n",
    "            # Sort scores (probably unecessary but just in case)\n",
    "            top_hits = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "            relevant_docs_ids = self.ground_truth[query_index]\n",
    "            # Accuracy@k - We count the result correct, if at least one relevant doc is across the top-k documents\n",
    "            found_any_acc_k = False\n",
    "            for k_val in self.accuracy_at_k:\n",
    "                for hit in top_hits[0:k_val]:\n",
    "                    if hit[1] in relevant_docs_ids:\n",
    "                        num_hits_at_k[k_val] += 1\n",
    "                        found_any_acc_k = True\n",
    "                        break\n",
    "            if not found_any_acc_k:\n",
    "                self.problematic_queries.add(query_index)\n",
    "\n",
    "            # Precision and Recall@k\n",
    "            for k_val in self.precision_recall_at_k:\n",
    "                num_correct = 0\n",
    "                for hit in top_hits[0:k_val]:\n",
    "                    if hit[1] in relevant_docs_ids:\n",
    "                        num_correct += 1\n",
    "                \n",
    "                precisions_at_k[k_val].append(num_correct / k_val)\n",
    "                recall_at_k[k_val].append(num_correct / len(relevant_docs_ids))\n",
    "\n",
    "            # @Mean Reciprocal Rank\n",
    "            for k_val in self.mrr_at_k:\n",
    "                for rank, hit in enumerate(top_hits[0:k_val]):\n",
    "                    if hit[1] in relevant_docs_ids:\n",
    "                        MRR[k_val] += 1.0 / (rank + 1)\n",
    "                        break\n",
    "\n",
    "            # NDCG@k (normalized discounted cumulative gain at k)\n",
    "            for k_val in self.ndcg_at_k:\n",
    "                dcg = 0\n",
    "                idcg = 0\n",
    "                for i in range(k_val):\n",
    "                    if i < len(top_hits):\n",
    "                        if top_hits[i][1] in relevant_docs_ids:\n",
    "                            dcg += 1 / np.log2(i + 2)\n",
    "                    idcg += 1 / np.log2(i + 2)\n",
    "                ndcg[k_val].append(dcg / idcg)\n",
    "            \n",
    "            # Map@k\n",
    "            for k_val in self.map_at_k:\n",
    "                num_correct = 0\n",
    "                sum_precisions = 0\n",
    "                for i, hit in enumerate(top_hits[0:k_val]):\n",
    "                    if hit[1] in relevant_docs_ids:\n",
    "                        num_correct += 1\n",
    "                        sum_precisions += num_correct / (i + 1)\n",
    "                avg_precision = sum_precisions / min(k_val, len(relevant_docs_ids))\n",
    "                AveP_at_k[k_val].append(avg_precision)\n",
    "\n",
    "            \n",
    "        # Compute averages\n",
    "        for k in num_hits_at_k:\n",
    "            num_hits_at_k[k] /= len(self.query_embeddings)\n",
    "\n",
    "        for k in precisions_at_k:\n",
    "            precisions_at_k[k] = np.mean(precisions_at_k[k])\n",
    "        \n",
    "        for k in recall_at_k:\n",
    "            recall_at_k[k] = np.mean(recall_at_k[k])\n",
    "\n",
    "        for k in MRR:\n",
    "            MRR[k] /= len(self.query_embeddings)\n",
    "            MRR[k] = 1/MRR[k]\n",
    "\n",
    "        for k in ndcg:\n",
    "            ndcg[k] = np.mean(ndcg[k])\n",
    "        \n",
    "        for k in AveP_at_k:\n",
    "            AveP_at_k[k] = np.mean(AveP_at_k[k])\n",
    "        \n",
    "        return {\n",
    "            \"accuracy@k\": num_hits_at_k,\n",
    "            \"precision@k\": precisions_at_k,\n",
    "            \"recall@k\": recall_at_k,\n",
    "            \"ndcg@k\": ndcg,\n",
    "            \"mrr@k\": MRR,\n",
    "            \"map@k\": AveP_at_k,\n",
    "        }\n",
    "    \n",
    "    def output_scores(self, scores):\n",
    "        \"\"\"\n",
    "        Outputs the evaluation metrics.\n",
    "        Args:\n",
    "            metrics (Dict[str, Dict[str, float]]): A dictionary mapping metric names to dictionaries mapping metric values to scores.\n",
    "        \"\"\"\n",
    "        for k in scores[\"accuracy@k\"]:\n",
    "            logger.info(\"Accuracy@{}: {:.2f}%\".format(k, scores[\"accuracy@k\"][k] * 100))\n",
    "\n",
    "        for k in scores[\"precision@k\"]:\n",
    "            logger.info(\"Precision@{}: {:.2f}%\".format(k, scores[\"precision@k\"][k] * 100))\n",
    "\n",
    "        for k in scores[\"recall@k\"]:\n",
    "            logger.info(\"Recall@{}: {:.2f}%\".format(k, scores[\"recall@k\"][k] * 100))\n",
    "\n",
    "        for k in scores[\"mrr@k\"]:\n",
    "            logger.info(\"MRR@{}: {:.4f} rank from top\".format(k, scores[\"mrr@k\"][k]))\n",
    "\n",
    "        for k in scores[\"ndcg@k\"]:\n",
    "            logger.info(\"NDCG@{}: {:.4f}% as good as ideal ranking\".format(k, scores[\"ndcg@k\"][k] * 100))\n",
    "\n",
    "        for k in scores[\"map@k\"]:\n",
    "            logger.info(\"MAP@{}: {:.4f}\".format(k, scores[\"map@k\"][k]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = f\"{base_dir}/embeddings_distilbert_base_uncased_mean_pooling/embeddings.npy\"\n",
    "query_embeddings_path = f\"{base_dir}/evaluation_dataset/query_embeddings.npy\"\n",
    "\n",
    "corpus_embeddings = np.load(embeddings_path)\n",
    "query_embeddings = np.load(query_embeddings_path)\n",
    "# convert to tensor\n",
    "corpus_embeddings = torch.from_numpy(corpus_embeddings)\n",
    "query_embeddings = torch.from_numpy(query_embeddings)\n",
    "#normalize\n",
    "corpus_embeddings = F.normalize(corpus_embeddings, p=2, dim=1)\n",
    "query_embeddings = F.normalize(query_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 14:49:37,664 - INFO - Accuracy@1: 61.36%\n",
      "2025-01-28 14:49:37,665 - INFO - Accuracy@3: 70.45%\n",
      "2025-01-28 14:49:37,665 - INFO - Accuracy@5: 80.68%\n",
      "2025-01-28 14:49:37,665 - INFO - Accuracy@10: 87.50%\n",
      "2025-01-28 14:49:37,666 - INFO - Precision@1: 61.36%\n",
      "2025-01-28 14:49:37,666 - INFO - Precision@3: 25.38%\n",
      "2025-01-28 14:49:37,666 - INFO - Precision@5: 17.27%\n",
      "2025-01-28 14:49:37,666 - INFO - Precision@10: 10.11%\n",
      "2025-01-28 14:49:37,667 - INFO - Recall@1: 53.27%\n",
      "2025-01-28 14:49:37,667 - INFO - Recall@3: 63.83%\n",
      "2025-01-28 14:49:37,667 - INFO - Recall@5: 72.92%\n",
      "2025-01-28 14:49:37,667 - INFO - Recall@10: 80.49%\n",
      "2025-01-28 14:49:37,668 - INFO - MRR@10: 1.4532 rank from top\n",
      "2025-01-28 14:49:37,668 - INFO - NDCG@10: 17.4391% as good as ideal ranking\n",
      "2025-01-28 14:49:37,668 - INFO - MAP@100: 0.6326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity function: cosine\n",
      "\n",
      "\n",
      "Found 11 highly problematic queries\n",
      "\"Zoom invitation on April 21, 2021\"\n",
      "\"Pat asking how i'm doing with Ukrain war\"\n",
      "\"United Airlines eTicket receipt for confirmation OY874S\"\n",
      "\"Customer Acquisition and Retention Weekly Issue 281 February 2020\"\n",
      "\"Mailio NFTs daily summary September 2022\"\n",
      "\"GLS 508912991 delivery notice\"\n",
      "\"Budget Rent A Car reservation reminder September 2021\"\n",
      "\"Akontacija DDPO junij 2020\"\n",
      "\"racun za april 2020\"\n",
      "\"CueMateAPISpec API changes from Pat\"\n",
      "\"San Francisco Java User Group workshop December 2023\"\n"
     ]
    }
   ],
   "source": [
    "ir_evaluator = MailioInformationRetrievalEvaluator(ground_truth, corpus_embeddings, query_embeddings)\n",
    "metrics = ir_evaluator.run()\n",
    "for name, score in metrics.items():\n",
    "    print(f\"Similarity function: {name}\")\n",
    "    ir_evaluator.output_scores(score)\n",
    "    print(\"\\n\")\n",
    "print(f\"Found {len(ir_evaluator.get_problematic_queries())} highly problematic queries\")\n",
    "for problem_query_index in ir_evaluator.get_problematic_queries():\n",
    "    print(df_queries.iloc[problem_query_index][\"query\"])\n",
    "# print(metrics[SimilarityFunction.COSINE.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
